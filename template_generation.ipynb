{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install dask_jobqueue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This doesn't import correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# way to run script example\n",
    "# python make_template_dask.py \\\n",
    "#  -dsets /dsets/*.HEAD -init_base ~/abin/MNI_2009c.nii.gz -ex_mode dry_run\n",
    "#\n",
    "import sys\n",
    "sys.path.append('/data/NIMH_SSCC/template_making/scripts')\n",
    "import copy\n",
    "from time import asctime\n",
    "\n",
    "# AFNI modules\n",
    "from afni_base import *\n",
    "from afni_util import *\n",
    "from option_list import *\n",
    "from db_mod import *\n",
    "import ask_me\n",
    "\n",
    "# parallelization library\n",
    "from dask_jobqueue import SLURMCluster\n",
    "from dask.distributed import Client\n",
    "from dask import delayed\n",
    "# def delayed(fn):\n",
    "#  return fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_help_string = \"\"\"\n",
    "    ===========================================================================\n",
    "    make_template_dask.py    make a template from a bunch of datasets\n",
    "\n",
    "    This Python script iteratively aligns datasets initially to an example base dataset\n",
    "    and then to each other to make a new common template.\n",
    "\n",
    "    ---------------------------------------------\n",
    "    REQUIRED OPTIONS:\n",
    "\n",
    "    -dsets   : names of input datasets\n",
    "    -init_base   : initial base template, mostly for AC-PC or similar rigid registration\n",
    "    -template_name : name of new template dataset\n",
    "\n",
    "    MAJOR OPTIONS:\n",
    "    -help       : this help message\n",
    "    -outdir ssss: put all output into a specific, new directory (default is iterative_template_dir)\n",
    "    -overwrite  : overwrite and replace existing datasets\n",
    "    -restart    : skip over preexisting results to continue as quickly as possibly with a restart\n",
    "\"\"\"\n",
    "# BEGIN common functions across scripts (loosely of course)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delayed(func ):\n",
    "    return func\n",
    "\n",
    "class RegWrap:\n",
    "    def __init__(self, label):\n",
    "    # software version (update for changes)\n",
    "    self.make_template_version = \"0.01\"\n",
    "    # user assigned path for anat and EPI\n",
    "    self.output_dir = 'iterative_template_dir'\n",
    "\n",
    "    self.label = label\n",
    "    self.valid_opts = None\n",
    "    self.user_opts = None\n",
    "    self.verb = 1    # a little talkative by default\n",
    "    self.save_script = ''  # save completed script into given file\n",
    "    self.rewrite = 0  # Do not recreate existing volumes\n",
    "    self.oexec = \"\"  # dry_run is an option\n",
    "    self.rmrm = 1   # remove temporary files\n",
    "    self.prep_only = 0  # do preprocessing only\n",
    "    self.odir = os.getcwd()\n",
    "\n",
    "    return\n",
    "\n",
    "    def init_opts(self):\n",
    "\n",
    "    self.valid_opts = OptionList('init_opts')\n",
    "\n",
    "    # input datasets\n",
    "    self.valid_opts.add_opt('-dsets', -1, [],\n",
    "                               helpstr=\"Names of datasets\")\n",
    "    self.valid_opts.add_opt('-init_base', 1, [],\n",
    "                               helpstr=\"Name of initial base dataset\")\n",
    "\n",
    "    self.valid_opts.add_opt('-keep_rm_files', 0, [],\n",
    "               helpstr=\"Don't delete any of the temporary files created here\")\n",
    "    self.valid_opts.add_opt('-prep_only', 0, [],\n",
    "               helpstr=\"Do preprocessing steps only without alignment\")\n",
    "    self.valid_opts.add_opt('-help', 0, [],\n",
    "               helpstr=\"The main help describing this program with options\")\n",
    "    self.valid_opts.add_opt('-limited_help', 0, [],\n",
    "               helpstr=\"The main help without all available options\")\n",
    "    self.valid_opts.add_opt('-option_help', 0, [],\n",
    "               helpstr=\"Help for all available options\")\n",
    "    self.valid_opts.add_opt('-version', 0, [],\n",
    "               helpstr=\"Show version number and exit\")\n",
    "    self.valid_opts.add_opt('-ver', 0, [],\n",
    "               helpstr=\"Show version number and exit\")\n",
    "    self.valid_opts.add_opt('-verb', 1, [],\n",
    "               helpstr=\"Be verbose in messages and options\")\n",
    "    self.valid_opts.add_opt('-save_script', 1, [],\n",
    "               helpstr=\"save executed script in given file\")\n",
    "\n",
    "    self.valid_opts.add_opt('-align_centers', 1, ['no'], ['yes', 'no', 'on', 'off'],\n",
    "               helpstr=\"align centers of datasets based on spatial\\n\"\n",
    "                       \"extents of the original volume\")\n",
    "    self.valid_opts.add_opt('-strip_dsets', 1, ['None'],\n",
    "                              ['3dSkullStrip', '3dAutomask', 'None'],\n",
    "               helpstr=\"Remove skull/outside head or neither\")\n",
    "    self.valid_opts.add_opt('-overwrite', 0, [],\n",
    "                               helpstr=\"Overwrite existing files\")\n",
    "\n",
    "    def dry_run(self):\n",
    "    if self.oexec != \"dry_run\":\n",
    "            return 0\n",
    "    else:\n",
    "            return 1\n",
    "\n",
    "    def apply_initial_opts(self, opt_list):\n",
    "    opt1 = opt_list.find_opt('-version')  # user only wants version\n",
    "    opt2 = opt_list.find_opt('-ver')\n",
    "    if ((opt1 != None) or (opt2 != None)):\n",
    "            # ps.version()\n",
    "            ps.ciao(0)   # terminate\n",
    "    opt = opt_list.find_opt('-verb')    # set and use verb\n",
    "    if opt != None: self.verb = int(opt.parlist[0])\n",
    "\n",
    "    opt = opt_list.find_opt('-save_script')  # save executed script\n",
    "    if opt != None: self.save_script = opt.parlist[0]\n",
    "\n",
    "    # user says it's okay to overwrite existing files\n",
    "    opt = self.user_opts.find_opt('-overwrite')\n",
    "    if opt != None:\n",
    "            print(\"setting option to rewrite\")\n",
    "            ps.rewrite = 1\n",
    "\n",
    "    opt = opt_list.find_opt('-ex_mode')    # set execute mode\n",
    "    if opt != None: self.oexec = opt.parlist[0]\n",
    "\n",
    "    opt = opt_list.find_opt('-keep_rm_files')    # keep temp files\n",
    "    if opt != None: self.rmrm = 0\n",
    "\n",
    "    opt = opt_list.find_opt('-prep_only')    # preprocessing only\n",
    "    if opt != None: self.prep_only = 1\n",
    "\n",
    "    opt = opt_list.find_opt('-help')    # does the user want help?\n",
    "    if opt != None:\n",
    "        ps.self_help(2)   # always give full help now by default\n",
    "        ps.ciao(0)  # terminate\n",
    "\n",
    "    opt = opt_list.find_opt('-limited_help')  # less help?\n",
    "    if opt != None:\n",
    "            ps.self_help()\n",
    "            ps.ciao(0)  # terminate\n",
    "\n",
    "    opt = opt_list.find_opt('-option_help')  # help for options only\n",
    "    if opt != None:\n",
    "            ps.self_help(1)\n",
    "            ps.ciao(0)  # terminate\n",
    "\n",
    "    opt = opt_list.find_opt('-suffix')\n",
    "    if opt != None:\n",
    "        self.suffix = opt.parlist[0]\n",
    "        if((opt==\"\") or (opt==\" \")) :\n",
    "            self.error_msg(\"Cannot have blank suffix\")\n",
    "            ps.ciao(1);\n",
    "\n",
    "    def get_user_opts(self):\n",
    "    self.valid_opts.check_special_opts(sys.argv) #ZSS March 2014\n",
    "    self.user_opts = read_options(sys.argv, self.valid_opts)\n",
    "    if self.user_opts == None: return 1 #bad\n",
    "    # no options: apply -help\n",
    "    if ( len(self.user_opts.olist) == 0 or \\\n",
    "           len(sys.argv) <= 1 ) :\n",
    "            ps.self_help()\n",
    "            ps.ciao(0)  # terminate\n",
    "    if self.user_opts.trailers:\n",
    "            opt = self.user_opts.find_opt('trailers')\n",
    "            if not opt:\n",
    "             print( \"** ERROR: seem to have trailers, but cannot find them!\")\n",
    "            else:\n",
    "             print( \"** ERROR: have invalid trailing args: %s\", opt.show())\n",
    "            return 1  # failure\n",
    "\n",
    "    # apply the user options\n",
    "    if self.apply_initial_opts(self.user_opts): return 1\n",
    "\n",
    "    if self.verb > 3:\n",
    "            self.show('------ found options ------ ')\n",
    "\n",
    "    return\n",
    "\n",
    "    def show(self, mesg=\"\"):\n",
    "    print('%s: %s' % (mesg, self.label))\n",
    "    if self.verb > 2: self.valid_opts.show('valid_opts: ')\n",
    "    self.user_opts.show('user_opts: ')\n",
    "\n",
    "    def info_msg(self, mesg=\"\"):\n",
    "        if(self.verb >= 1) :\n",
    "          print(\"#++ %s\" % mesg)\n",
    "    def error_msg(self, mesg=\"\"):\n",
    "        print(\"#**ERROR %s\" % mesg)\n",
    "\n",
    "    def exists_msg(self, dsetname=\"\"):\n",
    "        print(\"** Dataset: %s already exists\" % dsetname)\n",
    "        print(\"** Not overwriting.\")\n",
    "        if(not ps.dry_run()):\n",
    "           self.ciao(1)\n",
    "\n",
    "    def ciao(self, i):\n",
    "    if i > 0:\n",
    "            print( \"** ERROR - script failed\")\n",
    "    elif i==0:\n",
    "            print(\"\")\n",
    "\n",
    "    os.chdir(self.odir)\n",
    "\n",
    "    if self.save_script:\n",
    "            write_afni_com_history(self.save_script)\n",
    "\n",
    "    # return status code\n",
    "    sys.exit(i)\n",
    "\n",
    "    # save the script command arguments to the dataset history\n",
    "    def save_history(self, dset, exec_mode):\n",
    "    self.info_msg(\"Saving history\")  # sounds dramatic, doesn't it?\n",
    "    cmdline = args_as_command(sys.argv, \\\n",
    "                 '3dNotes -h \"', '\" %s' % dset.input())\n",
    "    com = shell_com(  \"%s\\n\" % cmdline, exec_mode)\n",
    "    com.run()\n",
    "\n",
    "    # show help\n",
    "    # if help_level is 1, then show options help only\n",
    "    # if help_level is 2, then show main help and options help\n",
    "    def self_help(self, help_level=0):\n",
    "    if(help_level!=1) :\n",
    "            print( g_help_string )\n",
    "    if(help_level):\n",
    "            print(\"A full list of options for %s:\\n\" % ps.label)\n",
    "            for opt in self.valid_opts.olist:\n",
    "            print(\"   %-20s\" % (opt.name ))\n",
    "            if (opt.helpstr != ''):\n",
    "               print( \"   %-20s   %s\" % \\\n",
    "                  (\"   use:\", opt.helpstr.replace(\"\\n\",\"\\n   %-20s   \"%' ')))\n",
    "            if (opt.acceptlist):\n",
    "               print( \"   %-20s   %s\" % \\\n",
    "                  (\"   allowed:\" , str.join(', ',opt.acceptlist)))\n",
    "            if (opt.deflist):\n",
    "               print( \"   %-20s   %s\" % \\\n",
    "                  (\"   default:\",str.join(' ',opt.deflist)))\n",
    "    return 1\n",
    "\n",
    "    def version(self):\n",
    "    self.info_msg(\"make_template_dask: %s\" % self.make_template_version)\n",
    "\n",
    "    # copy dataset 1 to dataset 2\n",
    "    # show message and check if dset1 is the same as dset2\n",
    "    # return non-zero error if can not copy\n",
    "    def copy_dset(self, dset1, dset2, message, exec_mode):\n",
    "    self.info_msg(message)\n",
    "    if(dset1.input()==dset2.input()):\n",
    "            print( \"# copy is not necessary\")\n",
    "            return 0\n",
    "#      if((os.path.islink(dset1.p())) or (os.path.islink(dset2.p()))):\n",
    "    if(dset1.real_input() == dset2.real_input()):\n",
    "            print( \"# copy is not necessary\")\n",
    "            return 0\n",
    "    ds1 = dset1.real_input()\n",
    "    ds2 = dset2.real_input()\n",
    "    ds1s = ds1.replace('/./','/')\n",
    "    ds2s = ds2.replace('/./','/')\n",
    "    if(ds1s == ds2s):\n",
    "        print( \"# copy is not necessary - both paths are same\" )\n",
    "        return 0\n",
    "    print(\"copying from dataset %s to %s\" % (dset1.input(), dset2.input()))\n",
    "    dset2.delete(exec_mode)\n",
    "    com = shell_com(  \\\n",
    "            \"3dcopy %s %s\" % (dset1.input(), dset2.out_prefix()), exec_mode)\n",
    "    com.run()\n",
    "    if ((not dset2.exist())and (exec_mode!='dry_run')):\n",
    "            print( \"** ERROR: Could not rename %s\\n\" % dset1.input())\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "# BEGIN script specific functions\n",
    "    def process_input(self):\n",
    "    # Do the default test on all options entered.\n",
    "    # NOTE that default options that take no parameters will not go\n",
    "    # through test, but that is no big deal\n",
    "    for opt in self.user_opts.olist:\n",
    "            if (opt.test() == None): ps.ciao(1)\n",
    "\n",
    "    # skull stripping is off by default\n",
    "    opt = self.user_opts.find_opt('-strip_dsets')\n",
    "    ps.skullstrip = 0\n",
    "    if opt != None :\n",
    "        ps.skullstrip_method = 'None'\n",
    "        ps.skullstrip_method = opt.parlist[0]\n",
    "        if(ps.skullstrip_method=='None'):\n",
    "            ps.skullstrip = 0\n",
    "        else:\n",
    "            ps.skullstrip = 1\n",
    "    opt = self.user_opts.find_opt('-dsets')\n",
    "    if opt != None:\n",
    "            opt = self.user_opts.find_opt('-dsets')\n",
    "            if opt == None:\n",
    "            print( \"** ERROR: Must use -dsets option to specify input datasets\\n\")\n",
    "            ps.ciao(1)\n",
    "    ps.dsets = self.user_opts.find_opt('-dsets')\n",
    "    for dset_name in ps.dsets.parlist:\n",
    "            check_dset = afni_name(dset_name)\n",
    "            if not check_dset.exist():\n",
    "            self.error_msg(\"Could not find dset\\n %s \"\n",
    "               % check_dset.input())\n",
    "            else:\n",
    "            self.info_msg(\n",
    "               \"Found dset %s\\n\" % check_dset.input())\n",
    "\n",
    "    if opt != None:\n",
    "            opt = self.user_opts.find_opt('-init_base')\n",
    "            if opt == None:\n",
    "            print( \"** ERROR: Must use -init_base option to specify an initial base\\n\")\n",
    "            ps.ciao(1)\n",
    "\n",
    "            ps.basedset = afni_name(opt.parlist[0])\n",
    "            if not ps.basedset.exist():\n",
    "                self.error_msg(\"Could not find initial base dataset\\n %s \"\n",
    "                % ps.basedset.input())\n",
    "            else:\n",
    "                self.info_msg(\n",
    "                \"Found initial base dset %s\\n\" % ps.basedset.input())\n",
    "\n",
    "\n",
    "    # align the center of a dataset to the center of another dataset like a template\n",
    "  @delayed\n",
    "    def align_centers(self,dset=None,base=None,suffix=\"_ac\"):\n",
    "        print(\"align centers of %s to %s\" % (dset.out_prefix(), base.out_prefix()) )\n",
    "\n",
    "        if(dset.type == 'NIFTI'):\n",
    "                # copy original to a temporary file\n",
    "                print(\"dataset input name is %s\" % dset.input())\n",
    "                ao = strip_extension(dset.input(), ['.nii','nii.gz'])\n",
    "            print(\"new AFNI name is %s\" % ao[0])\n",
    "                aao = afni_name(\"%s\"  % (ao[0]))\n",
    "                aao.to_afni(new_view=\"+orig\")\n",
    "                o = afni_name(\"%s%s%s\" % (aao.out_prefix(), suffix, aao.view))\n",
    "        else:\n",
    "                o = dset.new(\"%s%s\" % (dset.out_prefix(), suffix))\n",
    "\n",
    "        # use shift transformation of centers between grids as initial\n",
    "        # transformation. @Align_Centers (3drefit)\n",
    "        copy_cmd = \"3dcopy %s %s\" % (dset.input(), o.ppv())\n",
    "        cmd_str = \"%s; @Align_Centers -base %s -dset %s -no_cp\" %     \\\n",
    "                (copy_cmd, base.input(), o.input())\n",
    "        print(\"executing:\\n %s\" % cmd_str)\n",
    "        if (not o.exist() or ps.rewrite or ps.dry_run()):\n",
    "                o.delete(ps.oexec)\n",
    "                com = shell_com( cmd_str, ps.oexec)\n",
    "                com.run();\n",
    "                if (not o.exist() and not ps.dry_run()):\n",
    "                print( \"** ERROR: Could not align centers using \\n  %s\\n\" % cmd_str)\n",
    "                return None\n",
    "        else:\n",
    "                self.exists_msg(o.input())\n",
    "\n",
    "        return o\n",
    "\n",
    "    # automask - make simple mask\n",
    "    @delayed\n",
    "    def automask(self,dset=None,suffix=\"_am\"):\n",
    "    print(\"automask %s\" % dset.out_prefix() )\n",
    "\n",
    "    if(dset.type == 'NIFTI'):\n",
    "            # copy original to a temporary file\n",
    "            print(\"dataset input name is %s\" % dset.input())\n",
    "            ao = strip_extension(dset.input(), ['.nii','nii.gz'])\n",
    "            print(\"new AFNI name is %s\" % ao[0])\n",
    "            aao = afni_name(\"%s\"  % (ao[0]))\n",
    "            aao.to_afni(new_view=\"+orig\")\n",
    "            o = afni_name(\"%s%s%s\" % (aao.out_prefix(), suffix, aao.view))\n",
    "    else:\n",
    "            o = dset.new(\"%s%s\" % (dset.out_prefix(), suffix))\n",
    "    cmd_str = \"3dAutomask -apply_prefix %s %s\" %     \\\n",
    "            (o.out_prefix(), dset.input())\n",
    "    print(\"executing:\\n %s\" % cmd_str)\n",
    "    if (not o.exist() or ps.rewrite or ps.dry_run()):\n",
    "        o.delete(ps.oexec)\n",
    "            com = shell_com( cmd_str, ps.oexec)\n",
    "            com.run();\n",
    "            if (not o.exist() and not ps.dry_run()):\n",
    "            print( \"** ERROR: Could not unifize using \\n  %s\\n\" % cmd_str)\n",
    "            return None\n",
    "    else:\n",
    "            self.exists_msg(o.input())\n",
    "\n",
    "    return o\n",
    "    # unifize - bias-correct a dataset\n",
    "    @delayed\n",
    "    def unifize(self,dset=None,suffix=\"_un\"):\n",
    "    print(\"unifize %s\" % dset.out_prefix() )\n",
    "\n",
    "    if(dset.type == 'NIFTI'):\n",
    "            # copy original to a temporary file\n",
    "            print(\"dataset input name is %s\" % dset.input())\n",
    "            ao = strip_extension(dset.input(), ['.nii','nii.gz'])\n",
    "            print(\"new AFNI name is %s\" % ao[0])\n",
    "            aao = afni_name(\"%s\"  % (ao[0]))\n",
    "            aao.to_afni(new_view=\"+orig\")\n",
    "            o = afni_name(\"%s%s%s\" % (aao.out_prefix(), suffix, aao.view))\n",
    "    else:\n",
    "            o = dset.new(\"%s%s\" % (dset.out_prefix(), suffix))\n",
    "    cmd_str = \"3dUnifize -gm -prefix %s -input %s\" %     \\\n",
    "            (o.out_prefix(), dset.input())\n",
    "    print(\"executing:\\n %s\" % cmd_str)\n",
    "    if (not o.exist() or ps.rewrite or ps.dry_run()):\n",
    "            o.delete(ps.oexec)\n",
    "            com = shell_com( cmd_str, ps.oexec)\n",
    "            com.run();\n",
    "            if (not o.exist() and not ps.dry_run()):\n",
    "            print( \"** ERROR: Could not unifize using \\n  %s\\n\" % cmd_str)\n",
    "            return None\n",
    "    else:\n",
    "            self.exists_msg(o.input())\n",
    "\n",
    "    return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main:\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    ps = RegWrap('make_template_dask.py')\n",
    "\n",
    "    ps.init_opts()\n",
    "    ps.version()\n",
    "    rv = ps.get_user_opts()\n",
    "    if (rv != None): ps.ciao(1)\n",
    "\n",
    "    # process and check input params\n",
    "    ps.process_input()\n",
    "    # if(not (ps.process_input())):\n",
    "    #   ps.ciao(1)\n",
    "\n",
    "    # get rid of any previous temporary data\n",
    "    # ps.cleanup()\n",
    "    # setup a scheduler. the cluster object will manage this\n",
    "    # It's important to constrain the workers to ones that  default to the same networking.\n",
    "    # We can't mix infiniband with 10g ethernet nodes.\n",
    "    # The constraint argument to sbatch allows us to specify the ethernet nodes\n",
    "    cluster = SLURMCluster(\n",
    "     queue='quick',\n",
    "     memory =  \"8g\",\n",
    "     processes=1,\n",
    "     threads = 4,\n",
    "     job_extra = ['--constraint=10g'] )\n",
    "    #  interface = 'ib0',\n",
    "    print(\"starting %d workers!\" % len(ps.dsets.parlist))\n",
    "    # start workers for each and every subject\n",
    "    cluster.start_workers(len(ps.dsets.parlist))\n",
    "    # Create a Client object to use the cluster we set up\n",
    "    c = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    alldnames = []\n",
    "    # Lets use the cluster we setup using dask delayed\n",
    "    # from dask import delayed\n",
    "    for dset_name in ps.dsets.parlist:\n",
    "    start_dset = afni_name(dset_name)\n",
    "    # start off just aligning the centers of the datasets\n",
    "    aname = ps.align_centers(dset=start_dset, base=ps.basedset)\n",
    "    amname = ps.automask(dset=aname)\n",
    "    dname = ps.unifize(dset=amname)\n",
    "\n",
    "    alldnames.append(dname)\n",
    "\n",
    "    print(\"Configured first processing loop\")\n",
    "\n",
    "    # The following command executes the task graph that\n",
    "    # alldnames represents. This is non-blocking. We can continue\n",
    "    # our python session. Whenever we query the affine object\n",
    "    # we will be informed of its status.\n",
    "    affine = c.compute(alldnames)\n",
    "    # This is a blocking call and will return the results.\n",
    "    # We could run this immediately or wait until affine shows\n",
    "    # that the computation is finished.\n",
    "    c.gather(affine)\n",
    "\n",
    "    ps.ciao(0)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
